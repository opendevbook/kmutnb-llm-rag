{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a0f5eabc-e139-4e4e-b0c4-9339af9a56f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: sentence-transformers in /home/vagrant/.venv/lib/python3.12/site-packages (5.0.0)\n",
      "Requirement already satisfied: transformers<5.0.0,>=4.41.0 in /home/vagrant/.venv/lib/python3.12/site-packages (from sentence-transformers) (4.53.2)\n",
      "Requirement already satisfied: tqdm in /home/vagrant/.venv/lib/python3.12/site-packages (from sentence-transformers) (4.67.1)\n",
      "Requirement already satisfied: torch>=1.11.0 in /home/vagrant/.venv/lib/python3.12/site-packages (from sentence-transformers) (2.7.1)\n",
      "Requirement already satisfied: scikit-learn in /home/vagrant/.venv/lib/python3.12/site-packages (from sentence-transformers) (1.7.0)\n",
      "Requirement already satisfied: scipy in /home/vagrant/.venv/lib/python3.12/site-packages (from sentence-transformers) (1.16.0)\n",
      "Requirement already satisfied: huggingface-hub>=0.20.0 in /home/vagrant/.venv/lib/python3.12/site-packages (from sentence-transformers) (0.33.4)\n",
      "Requirement already satisfied: Pillow in /home/vagrant/.venv/lib/python3.12/site-packages (from sentence-transformers) (11.3.0)\n",
      "Requirement already satisfied: typing_extensions>=4.5.0 in /home/vagrant/.venv/lib/python3.12/site-packages (from sentence-transformers) (4.14.1)\n",
      "Requirement already satisfied: filelock in /home/vagrant/.venv/lib/python3.12/site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (3.18.0)\n",
      "Requirement already satisfied: numpy>=1.17 in /home/vagrant/.venv/lib/python3.12/site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (2.3.1)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/vagrant/.venv/lib/python3.12/site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (25.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /home/vagrant/.venv/lib/python3.12/site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (6.0.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /home/vagrant/.venv/lib/python3.12/site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (2024.11.6)\n",
      "Requirement already satisfied: requests in /home/vagrant/.venv/lib/python3.12/site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (2.32.4)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in /home/vagrant/.venv/lib/python3.12/site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (0.21.2)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in /home/vagrant/.venv/lib/python3.12/site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (0.5.3)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /home/vagrant/.venv/lib/python3.12/site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (2025.5.1)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.2 in /home/vagrant/.venv/lib/python3.12/site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (1.1.5)\n",
      "Requirement already satisfied: setuptools in /home/vagrant/.venv/lib/python3.12/site-packages (from torch>=1.11.0->sentence-transformers) (80.9.0)\n",
      "Requirement already satisfied: sympy>=1.13.3 in /home/vagrant/.venv/lib/python3.12/site-packages (from torch>=1.11.0->sentence-transformers) (1.14.0)\n",
      "Requirement already satisfied: networkx in /home/vagrant/.venv/lib/python3.12/site-packages (from torch>=1.11.0->sentence-transformers) (3.5)\n",
      "Requirement already satisfied: jinja2 in /home/vagrant/.venv/lib/python3.12/site-packages (from torch>=1.11.0->sentence-transformers) (3.1.6)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /home/vagrant/.venv/lib/python3.12/site-packages (from torch>=1.11.0->sentence-transformers) (12.6.77)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /home/vagrant/.venv/lib/python3.12/site-packages (from torch>=1.11.0->sentence-transformers) (12.6.77)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /home/vagrant/.venv/lib/python3.12/site-packages (from torch>=1.11.0->sentence-transformers) (12.6.80)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.5.1.17 in /home/vagrant/.venv/lib/python3.12/site-packages (from torch>=1.11.0->sentence-transformers) (9.5.1.17)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /home/vagrant/.venv/lib/python3.12/site-packages (from torch>=1.11.0->sentence-transformers) (12.6.4.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /home/vagrant/.venv/lib/python3.12/site-packages (from torch>=1.11.0->sentence-transformers) (11.3.0.4)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /home/vagrant/.venv/lib/python3.12/site-packages (from torch>=1.11.0->sentence-transformers) (10.3.7.77)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /home/vagrant/.venv/lib/python3.12/site-packages (from torch>=1.11.0->sentence-transformers) (11.7.1.2)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /home/vagrant/.venv/lib/python3.12/site-packages (from torch>=1.11.0->sentence-transformers) (12.5.4.2)\n",
      "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.3 in /home/vagrant/.venv/lib/python3.12/site-packages (from torch>=1.11.0->sentence-transformers) (0.6.3)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.26.2 in /home/vagrant/.venv/lib/python3.12/site-packages (from torch>=1.11.0->sentence-transformers) (2.26.2)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /home/vagrant/.venv/lib/python3.12/site-packages (from torch>=1.11.0->sentence-transformers) (12.6.77)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /home/vagrant/.venv/lib/python3.12/site-packages (from torch>=1.11.0->sentence-transformers) (12.6.85)\n",
      "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /home/vagrant/.venv/lib/python3.12/site-packages (from torch>=1.11.0->sentence-transformers) (1.11.1.6)\n",
      "Requirement already satisfied: triton==3.3.1 in /home/vagrant/.venv/lib/python3.12/site-packages (from torch>=1.11.0->sentence-transformers) (3.3.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /home/vagrant/.venv/lib/python3.12/site-packages (from sympy>=1.13.3->torch>=1.11.0->sentence-transformers) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/vagrant/.venv/lib/python3.12/site-packages (from jinja2->torch>=1.11.0->sentence-transformers) (3.0.2)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /home/vagrant/.venv/lib/python3.12/site-packages (from requests->transformers<5.0.0,>=4.41.0->sentence-transformers) (3.4.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/vagrant/.venv/lib/python3.12/site-packages (from requests->transformers<5.0.0,>=4.41.0->sentence-transformers) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/vagrant/.venv/lib/python3.12/site-packages (from requests->transformers<5.0.0,>=4.41.0->sentence-transformers) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/vagrant/.venv/lib/python3.12/site-packages (from requests->transformers<5.0.0,>=4.41.0->sentence-transformers) (2025.7.9)\n",
      "Requirement already satisfied: joblib>=1.2.0 in /home/vagrant/.venv/lib/python3.12/site-packages (from scikit-learn->sentence-transformers) (1.5.1)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /home/vagrant/.venv/lib/python3.12/site-packages (from scikit-learn->sentence-transformers) (3.6.0)\n",
      "Requirement already satisfied: einop in /home/vagrant/.venv/lib/python3.12/site-packages (0.0.1)\n",
      "Requirement already satisfied: einops>=0.4.0 in /home/vagrant/.venv/lib/python3.12/site-packages (from einop) (0.8.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install sentence-transformers\n",
    "!pip install einop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e44e385a-96bc-45f1-a37a-82006046160f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.04088951  0.02824118 -0.05546337 ... -0.00159979 -0.02763485\n",
      "   0.00845535]\n",
      " [-0.02109072  0.04304685 -0.05400291 ...  0.00845333 -0.09080566\n",
      "  -0.045714  ]\n",
      " [-0.04385765  0.02051526 -0.01604236 ... -0.01354666 -0.02235507\n",
      "   0.04201256]]\n",
      "Embedding shape: (3, 1024)\n",
      "Embedding size: 3 dimensions\n",
      "tensor([[1.0000, 0.4995, 0.4955],\n",
      "        [0.4995, 1.0000, 0.3746],\n",
      "        [0.4955, 0.3746, 1.0000]])\n"
     ]
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "# 1 โหลดโมเดล ทดสอบ \n",
    "# SentenceTransformers จะทำการ Download model ให้เราเอง อัตตโนมัติ\n",
    "model = SentenceTransformer('BAAI/bge-m3')\n",
    "#model = SentenceTransformer('nomic-ai/nomic-embed-text-v1.5', trust_remote_code=True)\n",
    "#model = SentenceTransformer('mixedbread-ai/mxbai-embed-large-v1')\n",
    "\n",
    "# 2 สร้าง embeddings\n",
    "sentences = [\"สวัสดีครับ\", \"ประเทศไทย\", \"การเรียนรู้ python\"]\n",
    "embeddings = model.encode(sentences)\n",
    "print(embeddings)\n",
    "\n",
    "print(f\"Embedding shape: {embeddings.shape}\")  # Output: (768,) or (1024,) depending on the model\n",
    "print(f\"Embedding size: {embeddings.shape[0]} dimensions\")\n",
    "\n",
    "# 3 คำนวน embedding similarities\n",
    "\n",
    "similarities = model.similarity(embeddings, embeddings)\n",
    "print(similarities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39f6dfcb-5495-45a9-bd88-bc33a5d0953e",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install psycopg2-binary\n",
    "!pip install numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a9c36d8-0c2a-4fe6-9d8f-e413f98ce64f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import psycopg2 \n",
    "\n",
    "conn = None  # Initialize to avoid NameError in finally\n",
    "try:\n",
    "\n",
    "    conn = psycopg2.connect(\n",
    "        dbname=\"vectordb\",\n",
    "        user=\"postgres\",\n",
    "        password=\"postgres\",\n",
    "        host=\"localhost\"\n",
    "    )\n",
    "    cursor = conn.cursor()\n",
    "    print(\"Connection established.\")\n",
    "    # ... your database operations here ...\n",
    "except Exception as err:\n",
    "    print(\"Something went wrong.\")\n",
    "    print(err)\n",
    "    \n",
    "finally:\n",
    "    # Cleanup resources in reverse order\n",
    "    if 'cursor' in locals() and cursor:  # Check if cursor exists\n",
    "        cursor.close()\n",
    "    if conn:  # Check if connection exists\n",
    "        conn.close()\n",
    "    print(\"Resources released.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "938954fe-02a6-4b59-9b04-17d3ded29f65",
   "metadata": {},
   "source": [
    "## Create table documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e08d3859-00c6-40fd-8c4d-91b992019100",
   "metadata": {},
   "outputs": [],
   "source": [
    "import psycopg2\n",
    "from psycopg2 import sql\n",
    "\n",
    "# Connect to your PostgreSQL database\n",
    "conn = psycopg2.connect(\n",
    "    dbname=\"vectordb\",\n",
    "    user=\"postgres\",\n",
    "    password=\"postgres\",\n",
    "    host=\"localhost\"\n",
    ")\n",
    "\n",
    "try:\n",
    "    with conn.cursor() as cur:\n",
    "        cur.execute(\"CREATE EXTENSION IF NOT EXISTS vector;\")\n",
    "        # Create table if it doesn't exist\n",
    "        cur.execute(\"\"\"\n",
    "            CREATE TABLE IF NOT EXISTS documents (\n",
    "                id serial PRIMARY KEY,\n",
    "                content text,\n",
    "                embedding vector(1024),\n",
    "                created_at timestamptz DEFAULT now()\n",
    "            );\n",
    "        \"\"\")\n",
    "        conn.commit()\n",
    "        print(\"Table created successfully or already exists\")\n",
    "        \n",
    "        # Verify table exists\n",
    "        cur.execute(\"\"\"\n",
    "            SELECT EXISTS (\n",
    "                SELECT FROM information_schema.tables \n",
    "                WHERE table_name = 'documents'\n",
    "            );\n",
    "        \"\"\")\n",
    "        exists = cur.fetchone()[0]\n",
    "        print(f\"Table exists: {exists}\")\n",
    "        \n",
    "except Exception as e:\n",
    "    print(f\"Error: {e}\")\n",
    "    conn.rollback()\n",
    "finally:\n",
    "    cur.close()  # ปิด Cursor ก่อน\n",
    "    conn.close() # แล้วปิด Connection\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3086fca6-81f0-4e58-b595-e314f2d3596e",
   "metadata": {},
   "source": [
    "## Chage to Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcd47d83-a405-46df-9f3b-b67cf58be087",
   "metadata": {},
   "outputs": [],
   "source": [
    "import psycopg2\n",
    "from psycopg2 import sql\n",
    "\n",
    "def create_vector_table(\n",
    "    dbname=\"vectordb\",\n",
    "    user=\"postgres\",\n",
    "    password=\"postgres\",\n",
    "    host=\"localhost\",\n",
    "    table_name=\"items\",\n",
    "    vector_dim=3\n",
    "):\n",
    "    \"\"\"\n",
    "    Creates a PostgreSQL table with a vector column if it doesn't exist.\n",
    "    \n",
    "    Args:\n",
    "        dbname (str): Database name\n",
    "        user (str): Database user\n",
    "        password (str): Database password\n",
    "        host (str): Database host\n",
    "        table_name (str): Name of the table to create\n",
    "        vector_dim (int): Dimension for the vector column\n",
    "        \n",
    "    Returns:\n",
    "        tuple: (success: bool, message: str)\n",
    "    \"\"\"\n",
    "    conn = None\n",
    "    try:\n",
    "        # Connect to PostgreSQL\n",
    "        conn = psycopg2.connect(\n",
    "            dbname=dbname,\n",
    "            user=user,\n",
    "            password=password,\n",
    "            host=host\n",
    "        )\n",
    "        \n",
    "        with conn.cursor() as cur:\n",
    "            # Ensure vector extension exists\n",
    "            cur.execute(\"CREATE EXTENSION IF NOT EXISTS vector;\")\n",
    "            \n",
    "            # Create table with vector column\n",
    "            cur.execute(sql.SQL(\"\"\"\n",
    "                CREATE TABLE IF NOT EXISTS {} (\n",
    "                    id serial PRIMARY KEY,\n",
    "                    content text,\n",
    "                    embedding vector({}),\n",
    "                    created_at timestamptz DEFAULT now(),\n",
    "                    metadata jsonb\n",
    "                );\n",
    "            \"\"\").format(\n",
    "                sql.Identifier(table_name),\n",
    "                sql.Literal(vector_dim)\n",
    "            ))\n",
    "            \n",
    "            conn.commit()\n",
    "            \n",
    "            # Verify table creation\n",
    "            cur.execute(sql.SQL(\"\"\"\n",
    "                SELECT column_name, data_type \n",
    "                FROM information_schema.columns \n",
    "                WHERE table_name = {};\n",
    "            \"\"\").format(sql.Literal(table_name)))\n",
    "            \n",
    "            columns = cur.fetchall()\n",
    "            column_names = [col[0] for col in columns]\n",
    "            \n",
    "            message = f\"Table '{table_name}' created with columns: {column_names}\"\n",
    "            return (True, message)\n",
    "            \n",
    "    except psycopg2.Error as e:\n",
    "        error_msg = f\"Database error occurred: {e}\"\n",
    "        if conn:\n",
    "            conn.rollback()\n",
    "        return (False, error_msg)\n",
    "        \n",
    "    except Exception as e:\n",
    "        error_msg = f\"Unexpected error: {e}\"\n",
    "        return (False, error_msg)\n",
    "        \n",
    "    finally:\n",
    "        if conn:\n",
    "            conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "949b19b6-40d8-44d1-bcbf-d4c7e55cb12e",
   "metadata": {},
   "outputs": [],
   "source": [
    "success, message = create_vector_table(\n",
    "        table_name=\"documents\",\n",
    "        vector_dim=1024  # For larger embeddings 768\n",
    ")\n",
    "print(f\"Success: {success}\")\n",
    "print(f\"Message: {message}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d883b84f-e7fc-463f-a3de-959cf63cd9e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import psycopg2\n",
    "from psycopg2 import sql\n",
    "\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "model = SentenceTransformer('BAAI/bge-m3')\n",
    "#model = SentenceTransformer('nomic-ai/nomic-embed-text-v1.5', trust_remote_code=True)\n",
    "#model = SentenceTransformer('mixedbread-ai/mxbai-embed-large-v1')\n",
    "\n",
    "conn = psycopg2.connect(\n",
    "    dbname=\"vectordb\",\n",
    "    user=\"postgres\",\n",
    "    password=\"postgres\",\n",
    "    host=\"localhost\"\n",
    ")\n",
    "\n",
    "def add_documents(text: str) -> bool:\n",
    "    \"\"\"\n",
    "    Adds a document to the PostgreSQL database with its text embedding.\n",
    "    \n",
    "    Args:\n",
    "        text: The text content to be stored\n",
    "        \n",
    "    Returns:\n",
    "        bool: True if successful, False if failed\n",
    "    \"\"\"\n",
    "    conn = None\n",
    "    try:\n",
    "        # Generate embedding\n",
    "        embedding = model.encode(text)\n",
    "        \n",
    "        # Connect to PostgreSQL\n",
    "        conn = psycopg2.connect(\n",
    "            dbname=\"vectordb\",\n",
    "            user=\"postgres\",\n",
    "            password=\"postgres\",\n",
    "            host=\"localhost\"\n",
    "        )\n",
    "        \n",
    "        with conn.cursor() as cur:\n",
    "            # Convert numpy array to PostgreSQL compatible format\n",
    "            embedding_list = embedding.tolist()\n",
    "            # Insert document and embedding\n",
    "            cur.execute(\n",
    "                \"INSERT INTO documents (content, embedding) VALUES (%s, %s)\",\n",
    "                (text, embedding_list)\n",
    "            )\n",
    "            conn.commit()\n",
    "        return True\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error adding document: {e}\")\n",
    "        if conn:\n",
    "            conn.rollback()\n",
    "        return False\n",
    "        \n",
    "    finally:\n",
    "        if conn:\n",
    "            conn.close()\n",
    "\n",
    "# data สำหรับการ Embedding\n",
    "documents = [\n",
    "    \"วันพุธ\t1 มกราคม\tวันขึ้นปีใหม่\",\n",
    "    \"วันพุธ\t12 กุมภาพันธ์\tวันมาฆบูชา\",\n",
    "    \"วันจันทร์\t7 เมษายน\tวันหยุดชดเชยวันจักรี\",\n",
    "    \"วันจันทร์\t14 เมษายน\tวันสงกรานต์\",\n",
    "    \"วันอังคาร\t15 เมษายน\tวันสงกรานต์\",\n",
    "    \"วันพฤหัสบดี\t1 พฤษภาคม\tวันแรงงานแห่งชาติ \",\n",
    "    \"วันจันทร์\t5 พฤษภาคม\tวันหยุดชดเชยวันฉัตรมงคล\",\n",
    "    \"วันศุกร์\t9 พฤษภาคม\tวันพืชมงคล (หยุดเฉพาะราชการ)\",\n",
    "    \"วันจันทร์\t12 พฤษภาคม\tวันหยุดชดเชยวันวิสาขบูชา\",\n",
    "    \"วันจันทร์\t2 มิถุนายน\tวันหยุดพิเศษ\",\n",
    "    \"วันอังคาร\t3 มิถุนายน\tวันเฉลิมพระชนมพรรษาสมเด็จพระนางเจ้าสุทิดา\",\n",
    "    \"วันพฤหัสบดี\t10 กรกฎาคม\tวันอาสาฬหบูชา\",\n",
    "    \"วันศุกร์\t11 กรกฎาคม\tวันเข้าพรรษา (หยุดเฉพาะราชการ)\",\n",
    "    \"วันจันทร์\t28 กรกฎาคม\tวันเฉลิมพระชนมพรรษาพระบาทสมเด็จพระเจ้าอยู่หัว\",\n",
    "    \"วันจันทร์\t11 สิงหาคม\tวันหยุดพิเศษ\",\n",
    "    \"วันอังคาร\t12 สิงหาคม\tวันแม่แห่งชาติ\",\n",
    "    \"วันจันทร์\t13 ตุลาคม\tวันนวมินทรมหาราช\",\n",
    "    \"วันพฤหัสบดี\t23 ตุลาคม\tวันปิยมหาราช\",\n",
    "    \"วันศุกร์\t5 ธันวาคม\tวันคล้ายวันพระราชสมภพรัชกาลที่ 9 วันชาติ และ วันพ่อแห่งชาติ\",\n",
    "    \"วันพุธ\t10 ธันวาคม\tวันรัฐธรรมนูญ\",\n",
    "    \"วันพุธ\t31 ธันวาคม\tวันสิ้นปี\",\n",
    "]\n",
    "\n",
    "for doc in documents:\n",
    "    add_documents(doc)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d74e8d30-d408-46b7-9798-af9c4357b3d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_five_documents():\n",
    "    \"\"\"\n",
    "    Prints the first 5 documents from the database for verification\n",
    "    \"\"\"\n",
    "    conn = None\n",
    "    try:\n",
    "        conn = psycopg2.connect(\n",
    "            dbname=\"vectordb\",\n",
    "            user=\"postgres\",\n",
    "            password=\"postgres\",\n",
    "            host=\"localhost\"\n",
    "        )\n",
    "        \n",
    "        \n",
    "        with conn.cursor() as cur:\n",
    "            cur.execute(\"SELECT id, content, embedding FROM documents LIMIT 5\")\n",
    "            rows = cur.fetchall()\n",
    "            \n",
    "            print(\"\\nVerifying documents (first 5 rows):\")\n",
    "            print(\"-\" * 50)\n",
    "            for row in rows:\n",
    "                print(f\"ID: {row[0]}\")\n",
    "                print(f\"Content: {row[1][:100]}...\")  # Print first 100 chars of content\n",
    "                print(f\"Embedding length: {len(row[2])}\")\n",
    "                print(\"-\" * 50)\n",
    "                \n",
    "    except Exception as e:\n",
    "        print(f\"Error fetching documents: {e}\")\n",
    "        \n",
    "    finally:\n",
    "        if conn:\n",
    "            conn.close()\n",
    "#Usage\n",
    "print_five_documents()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "88a16f53-fbfd-4b10-96f9-687499c62bfa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('วันพุธ\\t1 มกราคม\\tวันขึ้นปีใหม่', 0.3361233077122753), ('วันจันทร์\\t2 มิถุนายน\\tวันหยุดพิเศษ', 0.43126433268360187), ('วันพุธ\\t31 ธันวาคม\\tวันสิ้นปี', 0.47097019418629704), ('วันจันทร์\\t7 เมษายน\\tวันหยุดชดเชยวันจักรี', 0.47764746778152767), ('วันจันทร์\\t11 สิงหาคม\\tวันหยุดพิเศษ', 0.47934623124163445)]\n"
     ]
    }
   ],
   "source": [
    "import psycopg2\n",
    "from psycopg2 import sql\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "model = SentenceTransformer('BAAI/bge-m3')\n",
    "\n",
    "def query_postgresql(query_text, k=5):\n",
    "    query_embedding = model.encode(query_text).tolist()\n",
    "    # print(query_embedding)\n",
    "\n",
    "    # แปลง vector เป็น String\n",
    "    query_embedding_str = \"[\"+ \",\".join(map(str,query_embedding)) + \"]\"\n",
    "    # print(query_embedding_str)\n",
    "    \n",
    "    conn = None\n",
    "    try:\n",
    "        conn = psycopg2.connect(\n",
    "            dbname=\"vectordb\",\n",
    "            user=\"postgres\",\n",
    "            password=\"postgres\",\n",
    "            host=\"localhost\"\n",
    "        )\n",
    "        # <=> คำนวนควาเหมือน ยิ่งน้อย ยิ่งเหมือน\n",
    "        sql_query = \"\"\"\n",
    "            SELECT content, embedding <=> %s::vector AS similarity_score\n",
    "            FROM  documents\n",
    "            ORDER BY  similarity_score ASC\n",
    "            LIMIT %s\n",
    "        \"\"\"\n",
    "        \n",
    "        with conn.cursor() as cur:\n",
    "            cur.execute(sql_query,(query_embedding_str,k))\n",
    "            results = cur.fetchall()\n",
    "            \n",
    "        return results\n",
    "                \n",
    "    except Exception as e:\n",
    "        print(f\"Error fetching documents: {e}\")\n",
    "        \n",
    "    finally:\n",
    "        if conn:\n",
    "            conn.close()\n",
    "#Usage\n",
    "resutls = query_postgresql(\"วันหยุดเดือน มกราคม\")\n",
    "print(resutls)\n",
    "                           "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc9e2983-9581-4d36-9be4-11f681933cd5",
   "metadata": {},
   "source": [
    "## Use Ollama"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a9b73ef9-f139-4e45-9ffc-d48189353141",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting ollama\n",
      "  Downloading ollama-0.5.1-py3-none-any.whl.metadata (4.3 kB)\n",
      "Requirement already satisfied: httpx>=0.27 in /home/vagrant/.venv/lib/python3.12/site-packages (from ollama) (0.28.1)\n",
      "Collecting pydantic>=2.9 (from ollama)\n",
      "  Downloading pydantic-2.11.7-py3-none-any.whl.metadata (67 kB)\n",
      "Requirement already satisfied: anyio in /home/vagrant/.venv/lib/python3.12/site-packages (from httpx>=0.27->ollama) (4.9.0)\n",
      "Requirement already satisfied: certifi in /home/vagrant/.venv/lib/python3.12/site-packages (from httpx>=0.27->ollama) (2025.7.9)\n",
      "Requirement already satisfied: httpcore==1.* in /home/vagrant/.venv/lib/python3.12/site-packages (from httpx>=0.27->ollama) (1.0.9)\n",
      "Requirement already satisfied: idna in /home/vagrant/.venv/lib/python3.12/site-packages (from httpx>=0.27->ollama) (3.10)\n",
      "Requirement already satisfied: h11>=0.16 in /home/vagrant/.venv/lib/python3.12/site-packages (from httpcore==1.*->httpx>=0.27->ollama) (0.16.0)\n",
      "Collecting annotated-types>=0.6.0 (from pydantic>=2.9->ollama)\n",
      "  Downloading annotated_types-0.7.0-py3-none-any.whl.metadata (15 kB)\n",
      "Collecting pydantic-core==2.33.2 (from pydantic>=2.9->ollama)\n",
      "  Downloading pydantic_core-2.33.2-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.8 kB)\n",
      "Requirement already satisfied: typing-extensions>=4.12.2 in /home/vagrant/.venv/lib/python3.12/site-packages (from pydantic>=2.9->ollama) (4.14.1)\n",
      "Collecting typing-inspection>=0.4.0 (from pydantic>=2.9->ollama)\n",
      "  Downloading typing_inspection-0.4.1-py3-none-any.whl.metadata (2.6 kB)\n",
      "Requirement already satisfied: sniffio>=1.1 in /home/vagrant/.venv/lib/python3.12/site-packages (from anyio->httpx>=0.27->ollama) (1.3.1)\n",
      "Downloading ollama-0.5.1-py3-none-any.whl (13 kB)\n",
      "Downloading pydantic-2.11.7-py3-none-any.whl (444 kB)\n",
      "Downloading pydantic_core-2.33.2-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading annotated_types-0.7.0-py3-none-any.whl (13 kB)\n",
      "Downloading typing_inspection-0.4.1-py3-none-any.whl (14 kB)\n",
      "Installing collected packages: typing-inspection, pydantic-core, annotated-types, pydantic, ollama\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5/5\u001b[0m [ollama]2m3/5\u001b[0m [pydantic]\n",
      "\u001b[1A\u001b[2KSuccessfully installed annotated-types-0.7.0 ollama-0.5.1 pydantic-2.11.7 pydantic-core-2.33.2 typing-inspection-0.4.1\n"
     ]
    }
   ],
   "source": [
    "!pip install ollama\n",
    "\n",
    "import ollama"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c4d1d45-332c-43ab-806a-36ac69190e0d",
   "metadata": {},
   "source": [
    "## Test Ollama Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8fd4661-d60c-42a5-9cb3-05e2e4f894ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ollama\n",
    "\n",
    "prompt = \"ประเทศไทยมีประชากรเท่าไหร่\"  \n",
    "\n",
    "response = ollama.chat(\n",
    "    model=\"llama3\",  \n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "        {\"role\": \"user\", \"content\": prompt}\n",
    "    ]\n",
    ")\n",
    "\n",
    "print(response[\"message\"][\"content\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6c41ba1a-c2c9-49dc-bbb3-7fcc7e4d3ff4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "วันจันทร์\t14 เมษายน\tวันสงกรานต์\n",
      "วันอังคาร\t15 เมษายน\tวันสงกรานต์\n",
      "วันพุธ\t1 มกราคม\tวันขึ้นปีใหม่\n",
      "Answer the question base on context: \n",
      "วันจันทร์\t14 เมษายน\tวันสงกรานต์\n",
      "วันอังคาร\t15 เมษายน\tวันสงกรานต์\n",
      "วันพุธ\t1 มกราคม\tวันขึ้นปีใหม่\n",
      "\n",
      "Question วันสงกรานต์\n"
     ]
    }
   ],
   "source": [
    "import ollama\n",
    "\n",
    "def generate_response(query_text):\n",
    "    # 1. Retrieve relevant documents from PostgreSQL\n",
    "    retrieved_docs = query_postgresql(query_text, 3)  # Fixed typo in variable name\n",
    "    \n",
    "    # 2. Prepare context from retrieved documents\n",
    "    context = \"\\n\".join([doc[0] for doc in retrieved_docs])\n",
    "    print(\"=== Retrieved Context ===\")\n",
    "    print(context)\n",
    "    \n",
    "    # 3. Construct the prompt with context\n",
    "    prompt = f\"\"\"Answer the question based on the following context:\n",
    "{context}\n",
    "\n",
    "Question: {query_text}\n",
    "\"\"\"\n",
    "    print(\"\\n=== Generated Prompt ===\")\n",
    "    print(prompt)\n",
    "    \n",
    "    # 4. Generate response using Ollama\n",
    "    try:\n",
    "        response = ollama.chat(\n",
    "            model=\"llama3\",  # Corrected model name (no \"llama3.2\")\n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": \"You are a helpful assistant that answers questions about Thailand.\"},\n",
    "                {\"role\": \"user\", \"content\": prompt}\n",
    "            ]\n",
    "        )\n",
    "        \n",
    "        # 5. Return the generated response\n",
    "        generated_answer = response[\"message\"][\"content\"]\n",
    "        print(\"\\n=== Generated Answer ===\")\n",
    "        print(generated_answer)\n",
    "        return generated_answer\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error generating response: {e}\")\n",
    "        return None\n",
    "\n",
    "# Example usage\n",
    "generate_response(\"วันสงกรานต์\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d663415a-8c6e-42fc-92b2-e9dd42f4febd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Kernel_env",
   "language": "python",
   "name": "kernel_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
